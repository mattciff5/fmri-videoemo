{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from os.path import join as opj\n",
    "from os.path import join, exists, split\n",
    "\n",
    "import time\n",
    "import urllib.request\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import zipfile\n",
    "import glob\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from glmsingle.glmsingle import GLM_single\n",
    "import pandas as pd\n",
    "from nilearn import maskers\n",
    "from nilearn import plotting\n",
    "import tqdm\n",
    "import nibabel as nib\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.image import concat_imgs, mean_img\n",
    "import matplotlib.pyplot as plt\n",
    "import nilearn\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "from nilearn.plotting import plot_contrast_matrix\n",
    "\n",
    "default_n_threads = 64\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = f\"{default_n_threads}\"\n",
    "os.environ['MKL_NUM_THREADS'] = f\"{default_n_threads}\"\n",
    "os.environ['OMP_NUM_THREADS'] = f\"{default_n_threads}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Path principali ===\n",
    "base_dir = \"/srv/nfs-data/sisko/matteoc/fmri_emo/ds005047-1.0.6\"\n",
    "stimuli_metadata_path = os.path.join(base_dir, \"stimuli\", \"face_videos_stimuli_category_description.tsv\")\n",
    "events_label_column = \"emotion\"  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Caricamento metadati stimoli video ===\n",
    "metadata_df = pd.read_csv(stimuli_metadata_path, sep='\\t', index_col=None)\n",
    "metadata_df = metadata_df.reset_index() \n",
    "metadata_df = metadata_df.dropna(axis=1, how='all')\n",
    "\n",
    "metadata_df.columns = [\n",
    "    \"stimulus\", \"emotion_label\", \"gender_label\", \"ethnicity_label\",\n",
    "    \"actions\", \"expression\", \"description\", \n",
    "    *metadata_df.columns[len(metadata_df.columns)-1:]  \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stimulus</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>gender_label</th>\n",
       "      <th>ethnicity_label</th>\n",
       "      <th>actions</th>\n",
       "      <th>expression</th>\n",
       "      <th>description</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stimtrn_1.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>talking, smiling</td>\n",
       "      <td>smiling</td>\n",
       "      <td>This is a woman.She has black hair.She is talk...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stimtrn_2.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>talking，wagging her head，crying</td>\n",
       "      <td>crying</td>\n",
       "      <td>This  is  a little girl.She has black hair.To ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stimtrn_3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>smiling， her smile gradually grows larger.</td>\n",
       "      <td>smiling</td>\n",
       "      <td>This is a woman. She has  brown hair.She is sm...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stimtrn_4.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>talking，nodding his head</td>\n",
       "      <td>an angry emotion</td>\n",
       "      <td>This is a man. He has gray hair and a moustach...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stimtrn_5.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>lifts his head up</td>\n",
       "      <td>a neutral emotion</td>\n",
       "      <td>This is a man. He has black hair. He gradually...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>stimtst_1316.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>smiling</td>\n",
       "      <td>smiling</td>\n",
       "      <td>This is a woman. She has blond hair.She is smi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>stimtst_1317.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>talking</td>\n",
       "      <td>an angry emotion</td>\n",
       "      <td>This is a man.He has black hair and  a moustac...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>stimtst_1318.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>smiling</td>\n",
       "      <td>smiling</td>\n",
       "      <td>This is a woman. She has black hair.She is smi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>stimtst_1319.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>talking</td>\n",
       "      <td>a neutral emotion</td>\n",
       "      <td>This is a man.He has  black hair.He is talking...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>stimtst_1320.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>smiling，talking</td>\n",
       "      <td>smiling</td>\n",
       "      <td>This is a man.He is talking while smiling.The ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1320 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              stimulus  emotion_label  gender_label  ethnicity_label  \\\n",
       "0        stimtrn_1.mp4              1             1                1   \n",
       "1        stimtrn_2.mp4              2             1                1   \n",
       "2        stimtrn_3.mp4              1             1                1   \n",
       "3        stimtrn_4.mp4              2             2                2   \n",
       "4        stimtrn_5.mp4              3             2                1   \n",
       "...                ...            ...           ...              ...   \n",
       "1315  stimtst_1316.mp4              1             1                2   \n",
       "1316  stimtst_1317.mp4              2             2                2   \n",
       "1317  stimtst_1318.mp4              1             1                1   \n",
       "1318  stimtst_1319.mp4              3             2                2   \n",
       "1319  stimtst_1320.mp4              1             2                2   \n",
       "\n",
       "                                         actions         expression  \\\n",
       "0                               talking, smiling            smiling   \n",
       "1                talking，wagging her head，crying             crying   \n",
       "2     smiling， her smile gradually grows larger.            smiling   \n",
       "3                       talking，nodding his head   an angry emotion   \n",
       "4                              lifts his head up  a neutral emotion   \n",
       "...                                          ...                ...   \n",
       "1315                                     smiling            smiling   \n",
       "1316                                     talking   an angry emotion   \n",
       "1317                                     smiling            smiling   \n",
       "1318                                     talking  a neutral emotion   \n",
       "1319                             smiling，talking            smiling   \n",
       "\n",
       "                                            description Unnamed: 7  \n",
       "0     This is a woman.She has black hair.She is talk...        NaN  \n",
       "1     This  is  a little girl.She has black hair.To ...        NaN  \n",
       "2     This is a woman. She has  brown hair.She is sm...        NaN  \n",
       "3     This is a man. He has gray hair and a moustach...        NaN  \n",
       "4     This is a man. He has black hair. He gradually...        NaN  \n",
       "...                                                 ...        ...  \n",
       "1315  This is a woman. She has blond hair.She is smi...        NaN  \n",
       "1316  This is a man.He has black hair and  a moustac...        NaN  \n",
       "1317  This is a woman. She has black hair.She is smi...        NaN  \n",
       "1318  This is a man.He has  black hair.He is talking...        NaN  \n",
       "1319  This is a man.He is talking while smiling.The ...        NaN  \n",
       "\n",
       "[1320 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrai raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "\n",
    "# === Funzione per estrarre dati fMRI + label emozionale ===\n",
    "def extract_fmri_and_labels(subject_id, session_id=\"02\", task_name=\"face\", base_dir=\"your_base_dir_here\", metadata_df=None, events_label_column=\"expression\"):\n",
    "    func_dir = os.path.join(base_dir, f\"sub-{subject_id}\", f\"ses-{session_id}\", \"func\")\n",
    "    \n",
    "    all_runs_data = []\n",
    "\n",
    "    for file in os.listdir(func_dir):\n",
    "        if file.endswith(\"_bold.nii\") and f\"task-{task_name}\" in file:\n",
    "            # Estrai il run ID\n",
    "            run_id = file.split(\"_run-\")[1].split(\"_\")[0]\n",
    "            print(f\"Processing subject {subject_id}, run {run_id}...\")\n",
    "\n",
    "            # === Carica file NIfTI ===\n",
    "            nii_path = os.path.join(func_dir, file)\n",
    "            fmri_img = nib.load(nii_path)\n",
    "            fmri_data = fmri_img.get_fdata()  # shape: (x, y, z, timepoints)\n",
    "\n",
    "            # === Costruisci path del file eventi ===\n",
    "            events_file = f\"sub-{subject_id}_ses-{session_id}_task-{task_name}_run-{run_id}_events.tsv\"\n",
    "            events_file_path = os.path.join(func_dir, events_file)\n",
    "\n",
    "            if os.path.exists(events_file_path):\n",
    "                events_df = pd.read_csv(events_file_path, sep=\"\\t\")\n",
    "                print(events_df)\n",
    "                break\n",
    "\n",
    "                for idx, row in events_df.iterrows():\n",
    "                    stim_video_name = row[\"stim_file\"].split(\"/\")[-1]    \n",
    "                    # Cerca metadati stimolo nella tabella generale\n",
    "                    stim_meta = metadata_df[metadata_df[\"stimulus\"].str.contains(stim_video_name)]\n",
    "\n",
    "                    if not stim_meta.empty:\n",
    "                        expression = stim_meta.iloc[0][events_label_column]\n",
    "                        all_runs_data.append({\n",
    "                            \"subject\": subject_id,\n",
    "                            \"session\": session_id,\n",
    "                            \"run\": run_id,\n",
    "                            \"onset\": row[\"onset\"],\n",
    "                            \"duration\": row[\"duration\"],\n",
    "                            \"stim_file\": stim_video_name,\n",
    "                            \"expression\": expression,\n",
    "                            \"fmri_data\": fmri_data \n",
    "                        })\n",
    "\n",
    "    return all_runs_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject 01, run 01...\n",
      "    onset  duration                    stim_file  sti_started  sti_stopped  \\\n",
      "0      12         3     face-video/stimtrn_1.mp4    82.555083    85.588482   \n",
      "1      18         3     face-video/stimtrn_2.mp4    86.363600    89.380339   \n",
      "2      24         3     face-video/stimtrn_3.mp4    92.347333    95.363945   \n",
      "3      30         3     face-video/stimtrn_4.mp4    98.330823   101.347517   \n",
      "4      36         3  face-video/stimtrn_1321.mp4   104.347884   107.356015   \n",
      "..    ...       ...                          ...          ...          ...   \n",
      "63    390         3  face-video/stimtrn_1322.mp4   458.322435   461.339104   \n",
      "64    396         3    face-video/stimtrn_29.mp4   464.322800   467.339374   \n",
      "65    402         3    face-video/stimtrn_20.mp4   470.356253   473.364553   \n",
      "66    408         3     face-video/stimtrn_8.mp4   476.348308   479.356476   \n",
      "67    414         3    face-video/stimtrn_28.mp4   482.356837   485.365074   \n",
      "\n",
      "    key_fix  \n",
      "0       NaN  \n",
      "1       NaN  \n",
      "2       NaN  \n",
      "3       NaN  \n",
      "4       NaN  \n",
      "..      ...  \n",
      "63      NaN  \n",
      "64      NaN  \n",
      "65      NaN  \n",
      "66      NaN  \n",
      "67      NaN  \n",
      "\n",
      "[68 rows x 6 columns]\n",
      "len data:  0\n"
     ]
    }
   ],
   "source": [
    "# === Esempio: estrazione per un soggetto ===\n",
    "subject_id = \"01\"\n",
    "data = extract_fmri_and_labels(subject_id=subject_id, session_id=\"02\", task_name=\"face\", \n",
    "                                  base_dir=\"/srv/nfs-data/sisko/matteoc/fmri_emo/ds005047-1.0.6\", metadata_df=metadata_df)\n",
    "\n",
    "# === Visualizza estratti ===\n",
    "for d in data[0:3]:\n",
    "    print(f\"Soggetto {d['subject']} - Run {d['run']} - Stimolo: {d['stim_file']} - Emozione: {d['emotion']}\")\n",
    "    print(f\"fMRI shape: {d['fmri_data'].shape}\\n\")\n",
    "print('len data: ',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrati preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_fmri_and_labels_preproc(subject_id, session_id=\"01\", task_name=\"face\", base_dir=\"your_base_dir_here\", metadata_df=None, events_label_column=\"expression\"):\n",
    "    func_dir = os.path.join(base_dir, \"derivatives\", \"pre-processed_volume_data\", f\"sub-{subject_id}\", f\"ses-{session_id}\")\n",
    "    \n",
    "    all_runs_data = []\n",
    "\n",
    "    for file in os.listdir(func_dir):\n",
    "        if file.endswith(\"_bold.nii\") and f\"task-{task_name}\" in file and \"desc-volume\" in file:\n",
    "            match = re.search(r\"run[-_]?(\\d+)\", file)\n",
    "            if match:\n",
    "                run_id = match.group(1)\n",
    "                print(f\"Processing subject {subject_id}, run {run_id}...\")\n",
    "\n",
    "                # === Carica file NIfTI ===\n",
    "                nii_path = os.path.join(func_dir, file)\n",
    "                try:\n",
    "                    fmri_img = nib.load(nii_path)\n",
    "                    # fmri_data = fmri_img.get_fdata()\n",
    "                except Exception as e:\n",
    "                    print(f\"[!] Errore caricamento NIfTI: {file} – {e}\")\n",
    "                    continue\n",
    "\n",
    "                # === Carica events.tsv ===\n",
    "                events_file = f\"sub-{subject_id}_ses-{session_id}_task-{task_name}_run-{run_id}_events.tsv\"\n",
    "                events_path = os.path.join(func_dir.replace(\"derivatives/pre-processed_volume_data\", \"\"), \"func\", events_file)\n",
    "                run_events = []\n",
    "\n",
    "                if os.path.exists(events_path):\n",
    "                    try:\n",
    "                        events_df = pd.read_csv(events_path, sep=\"\\t\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"[!] Errore lettura events.tsv: {events_path} – {e}\")\n",
    "                        events_df = None\n",
    "                else:\n",
    "                    events_df = None\n",
    "\n",
    "                if events_df is not None and metadata_df is not None:\n",
    "                    for idx, row in events_df.iterrows():\n",
    "                        stim_file = row[\"stim_file\"].split(\"/\")[-1]\n",
    "                        stim_meta = metadata_df[metadata_df[\"stimulus\"].str.contains(stim_file, na=False)]\n",
    "\n",
    "                        expression = stim_meta.iloc[0][events_label_column] if not stim_meta.empty else None\n",
    "\n",
    "                        run_events.append({\n",
    "                            \"onset\": row[\"onset\"],\n",
    "                            \"duration\": row[\"duration\"],\n",
    "                            \"stim_file\": stim_file,\n",
    "                            \"expression\": expression\n",
    "                        })\n",
    "\n",
    "                all_runs_data.append({\n",
    "                    \"subject\": subject_id,\n",
    "                    \"session\": session_id,\n",
    "                    \"run\": run_id,\n",
    "                    \"fmri_data\": fmri_img,\n",
    "                    \"events\": run_events\n",
    "                })\n",
    "\n",
    "    return all_runs_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masker_from_example_image(example_img, strategy=\"epi\"):\n",
    "    masker = maskers.NiftiMasker(mask_strategy=strategy)\n",
    "    masker.fit(example_img)\n",
    "    report = masker.generate_report()\n",
    "    return masker, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Subject 01, Session 02 ==\n",
      "Processing subject 01, run 01...\n",
      "Processing subject 01, run 02...\n",
      "Processing subject 01, run 03...\n",
      "Processing subject 01, run 04...\n",
      "Processing subject 01, run 05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:13<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Subject 01, Session 03 ==\n",
      "Processing subject 01, run 01...\n",
      "Processing subject 01, run 02...\n",
      "Processing subject 01, run 03...\n",
      "Processing subject 01, run 04...\n",
      "Processing subject 01, run 05...\n",
      "Processing subject 01, run 06...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:16<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Subject 01, Session 04 ==\n",
      "Processing subject 01, run 01...\n",
      "Processing subject 01, run 02...\n",
      "Processing subject 01, run 03...\n",
      "Processing subject 01, run 04...\n",
      "Processing subject 01, run 05...\n",
      "Processing subject 01, run 06...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:16<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Subject 01, Session 05 ==\n",
      "Processing subject 01, run 01...\n",
      "Processing subject 01, run 02...\n",
      "Processing subject 01, run 03...\n",
      "Processing subject 01, run 04...\n",
      "Processing subject 01, run 05...\n",
      "Processing subject 01, run 06...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:16<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Subject 01, Session 06 ==\n",
      "Processing subject 01, run 01...\n",
      "Processing subject 01, run 02...\n",
      "Processing subject 01, run 03...\n",
      "Processing subject 01, run 04...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Subject 01, Session 07 ==\n",
      "Processing subject 01, run 01...\n",
      "Processing subject 01, run 02...\n",
      "Processing subject 01, run 03...\n",
      "Processing subject 01, run 04...\n",
      "Processing subject 01, run 05...\n",
      "Processing subject 01, run 06...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:02,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Errore masking run-01 ses-07: Expected 1160051200 bytes, got 272250757 bytes from /srv/nfs-data/sisko/matteoc/fmri_emo/ds005047-1.0.6/derivatives/pre-processed_volume_data/sub-01/ses-07/sub-01_ses-07_task-face_space-individual_desc-volume_run-01_bold.nii\n",
      " - could the file be damaged?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Errore masking run-02 ses-07: Expected 1160051200 bytes, got 280948763 bytes from /srv/nfs-data/sisko/matteoc/fmri_emo/ds005047-1.0.6/derivatives/pre-processed_volume_data/sub-01/ses-07/sub-01_ses-07_task-face_space-individual_desc-volume_run-02_bold.nii\n",
      " - could the file be damaged?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Errore masking run-03 ses-07: Expected 580025600 bytes, got 43370381 bytes from /srv/nfs-data/sisko/matteoc/fmri_emo/ds005047-1.0.6/derivatives/pre-processed_volume_data/sub-01/ses-07/sub-01_ses-07_task-face_space-individual_desc-volume_run-03_bold.nii\n",
      " - could the file be damaged?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:13<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Subject 01, Session 08 ==\n",
      "Processing subject 01, run 01...\n",
      "Processing subject 01, run 02...\n",
      "Processing subject 01, run 03...\n",
      "Processing subject 01, run 04...\n",
      "Processing subject 01, run 05...\n",
      "Processing subject 01, run 06...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Errore masking run-01 ses-08: Expected 580025600 bytes, got 198506903 bytes from /srv/nfs-data/sisko/matteoc/fmri_emo/ds005047-1.0.6/derivatives/pre-processed_volume_data/sub-01/ses-08/sub-01_ses-08_task-face_space-individual_desc-volume_run-01_bold.nii\n",
      " - could the file be damaged?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Errore masking run-02 ses-08: Expected 580025600 bytes, got 193981509 bytes from /srv/nfs-data/sisko/matteoc/fmri_emo/ds005047-1.0.6/derivatives/pre-processed_volume_data/sub-01/ses-08/sub-01_ses-08_task-face_space-individual_desc-volume_run-02_bold.nii\n",
      " - could the file be damaged?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:17<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Subject 01, Session 09 ==\n",
      "Processing subject 01, run 01...\n",
      "Processing subject 01, run 02...\n",
      "Processing subject 01, run 03...\n",
      "Processing subject 01, run 04...\n",
      "Processing subject 01, run 05...\n",
      "Processing subject 01, run 06...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:26<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Subject 01, Session 10 ==\n",
      "Processing subject 01, run 01...\n",
      "Processing subject 01, run 02...\n",
      "Processing subject 01, run 03...\n",
      "Processing subject 01, run 04...\n",
      "Processing subject 01, run 05...\n",
      "Processing subject 01, run 06...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:26<00:00,  4.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Subject 01, Session 11 ==\n",
      "Processing subject 01, run 01...\n",
      "Processing subject 01, run 02...\n",
      "Processing subject 01, run 03...\n",
      "Processing subject 01, run 04...\n",
      "Processing subject 01, run 05...\n",
      "Processing subject 01, run 06...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:05<00:10,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Errore masking run-02 ses-11: Expected 580025600 bytes, got 420393441 bytes from /srv/nfs-data/sisko/matteoc/fmri_emo/ds005047-1.0.6/derivatives/pre-processed_volume_data/sub-01/ses-11/sub-01_ses-11_task-face_space-individual_desc-volume_run-02_bold.nii\n",
      " - could the file be damaged?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:22<00:00,  3.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvato: data_01.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# subj 01 --> ses-02, run-02\n",
    "# subj 03 --> ses-02, run-01\n",
    "# subj 04 --> ses-02, run-05\n",
    "# subj 05 --> ses-02, run-01\n",
    "\n",
    "subject_id = \"01\"\n",
    "TR = 1.0\n",
    "hrf_delay_sec = 3\n",
    "window_sec = 3\n",
    "hrf_delay_vol = int(hrf_delay_sec / TR)\n",
    "window_vols = int(window_sec / TR)\n",
    "base_dir = \"/srv/nfs-data/sisko/matteoc/fmri_emo/ds005047-1.0.6\"\n",
    "example_img_path = os.path.join(base_dir, \"derivatives\", \"pre-processed_volume_data\", f\"sub-{subject_id}\", f\"ses-02\", f\"sub-{subject_id}_ses-02_task-face_space-individual_desc-volume_run-02_bold.nii\")\n",
    "example_img = nib.load(example_img_path)\n",
    "masker, report = create_masker_from_example_image(example_img)\n",
    "\n",
    "subject_data = {}\n",
    "save_dir = '/srv/nfs-data/sisko/matteoc/fmri_emo/data_save'\n",
    "\n",
    "# === Ciclo sulle sessioni\n",
    "for session_id in [f\"{i:02d}\" for i in range(2, 12)]:  # da 02 a 11\n",
    "    print(f\"\\n== Subject {subject_id}, Session {session_id} ==\")\n",
    "    \n",
    "    session_runs = extract_fmri_and_labels_preproc(\n",
    "        subject_id=subject_id,\n",
    "        session_id=session_id,\n",
    "        task_name=\"face\",\n",
    "        base_dir=base_dir,\n",
    "        metadata_df=metadata_df,\n",
    "        events_label_column=\"expression\"\n",
    "    )\n",
    "\n",
    "    for item in tqdm.tqdm(session_runs):\n",
    "        fmri_segments = []\n",
    "        run_id = int(item[\"run\"])\n",
    "        set_type = \"train\" if run_id <= 4 else \"test\"\n",
    "        item[\"set_type\"] = set_type\n",
    "\n",
    "        if isinstance(item[\"fmri_data\"], nib.Nifti1Image):\n",
    "            try:\n",
    "                masked_data = masker.transform_single_imgs(item[\"fmri_data\"]).T\n",
    "                cleaned_data = nilearn.signal.clean(masked_data.T, detrend=True, standardize=True, t_r=TR)\n",
    "            except Exception as e:\n",
    "                print(f\"[!] Errore masking run-{item['run']} ses-{item['session']}: {e}\")\n",
    "                continue\n",
    "\n",
    "            for event in item[\"events\"]:\n",
    "                onset = event[\"onset\"]\n",
    "                start_vol = int(onset // TR) + hrf_delay_vol\n",
    "                end_vol = start_vol + window_vols\n",
    "                if end_vol <= cleaned_data.shape[0]:\n",
    "                    segment = cleaned_data[start_vol:end_vol, :]  # (3, num_voxels)\n",
    "                    fmri_segments.append(segment)\n",
    "                else:\n",
    "                    print(f\"⚠ Evento troppo vicino alla fine del run. Skippato.\")\n",
    "\n",
    "            item[\"fmri_data\"] = fmri_segments\n",
    "\n",
    "        else:\n",
    "            print(f\"⚠ Non-Nifti image found in item, skipping: {type(item['fmri_data'])}\")\n",
    "    \n",
    "    session_key = f\"ses-{session_id}\"\n",
    "    subject_data[session_key] = session_runs\n",
    "        \n",
    "with open(os.path.join(save_dir, f\"data_{subject_id}.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(subject_data, f)\n",
    "print(f\"Salvato: data_{subject_id}.pkl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subject_data['ses-02'][0]['fmri_data'])    #  60 + OneBack + BlankTrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_data['ses-02'][4]['set_type']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stimtst_1201.mp4\n",
      "stimtst_1202.mp4\n",
      "stimtst_1202.mp4\n",
      "stimtst_1203.mp4\n",
      "stimtst_1204.mp4\n",
      "stimtst_1205.mp4\n",
      "stimtst_1206.mp4\n",
      "stimtst_1207.mp4\n",
      "stimtst_1208.mp4\n",
      "stimtst_1209.mp4\n",
      "stimtst_1322.mp4\n",
      "stimtst_1211.mp4\n",
      "stimtst_1212.mp4\n",
      "stimtst_1213.mp4\n",
      "stimtst_1214.mp4\n",
      "stimtst_1215.mp4\n",
      "stimtst_1216.mp4\n",
      "stimtst_1217.mp4\n",
      "stimtst_1218.mp4\n",
      "stimtst_1219.mp4\n",
      "stimtst_1219.mp4\n",
      "stimtst_1220.mp4\n",
      "stimtst_1221.mp4\n",
      "stimtst_1222.mp4\n",
      "stimtst_1223.mp4\n",
      "stimtst_1224.mp4\n",
      "stimtst_1225.mp4\n",
      "stimtst_1226.mp4\n",
      "stimtst_1227.mp4\n",
      "stimtst_1228.mp4\n",
      "stimtst_1229.mp4\n",
      "stimtst_1321.mp4\n",
      "stimtst_1230.mp4\n",
      "stimtst_1210.mp4\n",
      "stimtst_1223.mp4\n",
      "stimtst_1212.mp4\n",
      "stimtst_1203.mp4\n",
      "stimtst_1204.mp4\n",
      "stimtst_1205.mp4\n",
      "stimtst_1209.mp4\n",
      "stimtst_1207.mp4\n",
      "stimtst_1202.mp4\n",
      "stimtst_1206.mp4\n",
      "stimtst_1218.mp4\n",
      "stimtst_1222.mp4\n",
      "stimtst_1321.mp4\n",
      "stimtst_1213.mp4\n",
      "stimtst_1213.mp4\n",
      "stimtst_1214.mp4\n",
      "stimtst_1225.mp4\n",
      "stimtst_1216.mp4\n",
      "stimtst_1226.mp4\n",
      "stimtst_1210.mp4\n",
      "stimtst_1219.mp4\n",
      "stimtst_1230.mp4\n",
      "stimtst_1230.mp4\n",
      "stimtst_1221.mp4\n",
      "stimtst_1211.mp4\n",
      "stimtst_1201.mp4\n",
      "stimtst_1224.mp4\n",
      "stimtst_1215.mp4\n",
      "stimtst_1217.mp4\n",
      "stimtst_1227.mp4\n",
      "stimtst_1322.mp4\n",
      "stimtst_1229.mp4\n",
      "stimtst_1220.mp4\n",
      "stimtst_1208.mp4\n",
      "stimtst_1228.mp4\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(subject_data['ses-02'][4]['events'])):\n",
    "    print(subject_data['ses-02'][4]['events'][i]['stim_file'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-meg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
